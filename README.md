

# ğŸ“„ `README.md`

```markdown
# ğŸŒ€ Naruto Hand Sign Recognition (Real-Time)

A real-time Naruto hand seal recognition system built using  
MediaPipe + Landmark-Based ML + Scikit-Learn.

This project dynamically tracks single and two-hand seals and predicts them in real time using a trained neural network model.

---

## ğŸš€ Features

- âœ… Real-time hand tracking (CPU friendly)
- âœ… Single & two-hand seal support
- âœ… 126-dimension landmark feature vector
- âœ… Wrist-relative normalization
- âœ… Data augmentation (flip, rotate, brightness, zoom)
- âœ… MLP-based classifier
- âœ… Dynamic prediction smoothing
- âœ… Stable live recognition
- âœ… Ready for WebSocket & Three.js integration

---

## ğŸ§  How It Works

1. MediaPipe detects hand landmarks (21 points per hand)
2. Landmarks are normalized relative to wrist
3. Left + Right hands are merged into a 126-dim vector
4. Model predicts the Naruto seal
5. Temporal smoothing ensures stable output

Pipeline:

```

Webcam â†’ MediaPipe â†’ Normalize â†’ MLP Model â†’ Smooth Output â†’ Display

```

---

## ğŸ“ Project Structure

```

naruto-hand-sign-recognition/
â”‚
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ bird/
â”‚       â”œâ”€â”€ boar/
â”‚       â”œâ”€â”€ dog/
â”‚       â”œâ”€â”€ horse/
â”‚       â”œâ”€â”€ monkey/
â”‚       â”œâ”€â”€ ram/
â”‚       â”œâ”€â”€ snake/
â”‚       â””â”€â”€ tiger/
â”‚
â”œâ”€â”€ dataset_webcam/        # Optional real webcam samples
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ naruto_seal_model.pkl
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ live_dynamic_recognition.py
â”‚   â”œâ”€â”€ webcam_dataset_collector.py
â”‚   â””â”€â”€ hand_skeleton_test.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

```

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Install Python (Recommended: 3.10)

Check version:

```

python --version

```

### 2ï¸âƒ£ Install Dependencies

```

pip install -r requirements.txt

```

---

## ğŸ‹ï¸ Training the Model

Make sure your dataset is placed in:

```

dataset/test/<seal_name>/*.jpg

```

Then run:

```

python src/train_model.py

```

Output includes:

- Training accuracy
- Validation accuracy
- Confusion matrix
- Model saved to `models/`

---

## ğŸ¥ Real-Time Dynamic Recognition

Run:

```

python src/live_dynamic_recognition.py

```

Features:

- Continuous tracking
- Majority vote smoothing
- Stable seal display
- Works for single & two-hand poses

---

## ğŸ“¸ Add Real Webcam Samples (Optional)

To improve accuracy:

```

python src/webcam_dataset_collector.py

```

- Press `S` to save sample
- Press `N` to switch seal
- Press `Q` to quit

Then retrain.

---

## ğŸ“Š Model Details

- Architecture: MLP (256 â†’ 128 â†’ 64)
- Activation: ReLU
- Optimizer: Adam
- Epochs: 350
- Feature Size: 126 (Left 63 + Right 63)
- Normalization: Wrist-relative scaling
- Validation Accuracy: ~92â€“95%

---

## ğŸ’¡ Performance Notes

- Runs entirely on CPU
- No GPU required
- Real-time capable (~20â€“30 FPS)
- Accuracy improves with real webcam samples

---

## ğŸ”® Next Steps

- WebSocket backend integration
- Three.js jutsu animation triggering
- Confidence-based animation control
- Temporal seal detection sequences
- Model export for web deployment

---

## ğŸ§© Tech Stack

- Python
- OpenCV
- MediaPipe
- Scikit-Learn
- NumPy
- Joblib

---

## ğŸ“œ License

This project is for educational and experimental purposes.

Naruto and related content belong to their respective copyright owners.

---

## ğŸ‘¨â€ğŸ’» Author

Naruto Hand Sign Recognition  
Built with passion for Computer Vision & Anime âš¡
```

---


Just tell me.
